{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FYRuPyTcF9c",
        "outputId": "bba7c5e7-881a-4914-cfb9-e0e4eb8c4d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Round 1\n",
            "ðŸš« No confident samples this round.\n",
            "\n",
            "ðŸ§ª Predictions on new data:\n",
            "Absolutely great experience => Positive\n",
            "So bad and boring => Negative\n",
            "Brilliantly directed => Negative\n",
            "Poor screenplay => Negative\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Sample dataset\n",
        "texts = [\n",
        "    \"I loved this movie\", \"What a fantastic film\", \"Absolutely great experience\",\n",
        "    \"This movie was terrible\", \"I hated the acting\", \"Worst movie ever\",\n",
        "    \"A masterpiece of cinema\", \"Horrible direction\", \"Great plot and story\", \"Boring and slow\"\n",
        "]\n",
        "labels = [1, 1, 1, 0, 0, 0, 1, 0, 1, 0]  # 1 = Positive, 0 = Negative\n",
        "\n",
        "# Step 2: Manual selection to balance classes\n",
        "X_labeled_texts = [\n",
        "    \"I loved this movie\",           # Positive\n",
        "    \"Absolutely great experience\",  # Positive\n",
        "    \"Worst movie ever\",             # Negative\n",
        "    \"I hated the acting\"            # Negative\n",
        "]\n",
        "y_labeled = [1, 1, 0, 0]\n",
        "\n",
        "# Use remaining as unlabeled\n",
        "X_unlabeled_texts = [\n",
        "    \"What a fantastic film\",        # Positive\n",
        "    \"This movie was terrible\",      # Negative\n",
        "    \"A masterpiece of cinema\",      # Positive\n",
        "    \"Horrible direction\",           # Negative\n",
        "    \"Great plot and story\",         # Positive\n",
        "    \"Boring and slow\"               # Negative\n",
        "]\n",
        "\n",
        "\n",
        "# Step 3: Define two views (BOW and TF-IDF)\n",
        "vectorizer1 = CountVectorizer()\n",
        "vectorizer2 = TfidfVectorizer()\n",
        "\n",
        "X1_labeled = vectorizer1.fit_transform(X_labeled_texts)\n",
        "X2_labeled = vectorizer2.fit_transform(X_labeled_texts)\n",
        "\n",
        "X1_unlabeled = vectorizer1.transform(X_unlabeled_texts)\n",
        "X2_unlabeled = vectorizer2.transform(X_unlabeled_texts)\n",
        "\n",
        "# Step 4: Initialize models\n",
        "model1 = MultinomialNB()\n",
        "model2 = MultinomialNB()\n",
        "\n",
        "# Step 5: Co-training loop\n",
        "for round_num in range(2):\n",
        "    print(f\"\\nðŸ” Round {round_num+1}\")\n",
        "\n",
        "    model1.fit(X1_labeled, y_labeled)\n",
        "    model2.fit(X2_labeled, y_labeled)\n",
        "\n",
        "    probs1 = model1.predict_proba(X1_unlabeled)\n",
        "    probs2 = model2.predict_proba(X2_unlabeled)\n",
        "\n",
        "    confident_idx = []\n",
        "    for i, (p1, p2) in enumerate(zip(probs1, probs2)):\n",
        "        if max(p1) > 0.9 and max(p2) > 0.9 and np.argmax(p1) == np.argmax(p2):\n",
        "            confident_idx.append(i)\n",
        "\n",
        "    if not confident_idx:\n",
        "        print(\"ðŸš« No confident samples this round.\")\n",
        "        break\n",
        "\n",
        "    # Add confident predictions to labeled set\n",
        "    X1_new = X1_unlabeled[confident_idx]\n",
        "    X2_new = X2_unlabeled[confident_idx]\n",
        "    y_new = model1.predict(X1_new)\n",
        "\n",
        "    X1_labeled = np.vstack([X1_labeled.toarray(), X2_new.toarray()])\n",
        "    X2_labeled = np.vstack([X2_labeled.toarray(), X1_new.toarray()])\n",
        "    y_labeled = np.concatenate([y_labeled, y_new])\n",
        "\n",
        "    # Remove used samples\n",
        "    remaining = [i for i in range(X1_unlabeled.shape[0]) if i not in confident_idx]\n",
        "    X1_unlabeled = X1_unlabeled[remaining]\n",
        "    X2_unlabeled = X2_unlabeled[remaining]\n",
        "\n",
        "    print(f\"âœ… Added {len(confident_idx)} new samples.\")\n",
        "\n",
        "# Step 6: Evaluate\n",
        "test_texts = [\"Absolutely great experience\", \"So bad and boring\", \"Brilliantly directed\", \"Poor screenplay\"]\n",
        "X1_test = vectorizer1.transform(test_texts)\n",
        "y_pred = model1.predict(X1_test)\n",
        "\n",
        "print(\"\\nðŸ§ª Predictions on new data:\")\n",
        "for text, pred in zip(test_texts, y_pred):\n",
        "    print(f\"{text} => {'Positive' if pred == 1 else 'Negative'}\")\n"
      ]
    }
  ]
}